# 《C++并发编程实战》学习笔记

字处理软件，实际上就是文本编辑器。

> 在 应用 软件 内部， 一种 并发 方式 是， 将 一个 应用 软件 拆分 成 多个 独立 进程 同时 运行， 它们 都 只 含 单一 线程， 非常 类似于 同时 运行 浏览器 和 文字处理 软件在 应用 软件 内部， 一种 并发 方式 是， 将 一个 应用 软件 拆分 成 多个 独立 进程 同时 运行， 它们 都 只 含 单一 线程， 非常 类似于 同时 运行 浏览器 和 文字处理 软件。
>
> 安东尼·威廉姆斯. C++并发编程实战（第2版）（C++标准委员会成员著作，破解C++多线程魔法，让并发编程不再困难！） (p. 40). 人民邮电出版社. Kindle Edition. 



Erlang 是进程环境的。

> 某些 编程 环境 以 进程 作为 基本 构建 单元， 其 并发 效果 确实 一流， 譬如 为 Erlang 编程 语言 准备 的 环境。
>



C++ 没有封装进程间通信。

> 因此， 即使 共享 内存 带来 隐患， 主流 语言 大都 青睐 以多 线程 的 方式 实现 并发 功能， 当中 也 包括 C++。 再加 上 C++ 本身 尚不 直接 支持 进程 间 通信， 所以 采用 多 进程 的 应用 软件 将不 得不 依赖于 平台 专属 的 应用 程序 接口（ Application Program Interface， API）。 鉴于 此， 本书 专攻 多 线程 并发， 后文 再提 及 并发， 便 假定 采用 多 线程 实现。
>



并发跟并行，其实是一个意思。

> 就多 线程 代码 而言， 并发 与 并行（ parallel） 的 含义 很大 程度 上相 互 重叠。 确实， 在 多数人 看来， 它们 就是 相同 的。 二者 差别 甚小， 主要 是 着眼点 和 使用 意图 不同。 两个 术语 都是 指使 用 可 调配 的 硬件 资源 同时 运行 多个 任务， 但 并行 更 强调 性能。 当人 们 谈及 并行 时， 主要 关心 的 是 利用 可 调配 的 硬件 资源 提升 大规模 数据处理 的 性能； 当 谈及 并发 时， 主要 关心 的 是 分离 关注 点 或 响应 能力。 这 两个 术语 之间 并非 泾渭分明， 它们 之间 仍有 很大 程度 的 重叠， 知晓 这点 会对 后文 的 讨论 有所 帮助， 两者 的 范例 将 穿插 本书。
>



我们要自己切换任务，也就是主动让出 CPU 。

> 若不 直接 使用 并发 技术， 我们将 不得不 编写 框架 做 任务 切换， 或者 不得 不在 某个 操作步骤 中， 频繁 调用 无关 领域 的 代码。
>



使用线程，有时候是设计思维，为了分离不同的任务的。

> 这样， 线程 的 实际 数量 便与 CPU 既有 的 内核 数量 无关， 因为 用 线程 分离 关注 点 的 依据 是 设计 理念， 不以 增加 运算 吞吐量 为 目的。
>



数据并行 与 任务分解。

> 任务 分解 可以 针对 处理 过程， 调度 某 线程 运行 同一 算法 的 某部 分， 另一 线程 则 运行 其他 部分； 也可以 针对 数据， 线程 分别 对 数据 的 不同 部分 执行 同样 的 操作， 这 被称为 数据 并行。
>



线程的启动本身也要时间。

> 时间。 假如 子 线程 上 运行 的 任务 太快 完成， 处理 任务 本身 的 时间 就会 远 短 于 线程 启动 的 时间， 结果， 应用 程序 的 整体 性能 很可能 还不 如 完全 由 主线 程 直接 执行任务 的 性能。
>



线程的栈一般是 1M。

> 假定 每个 线程 栈 的 大小 都是 1MB（ 这个 大小 常见 于 许多 系统）
>



C++ 11 带来的线程库可以跨平台。

> 以 标准化 形式 借 多 线程 支持 并发 是 C++ 的 新 特性。 C++ 11 标准 发布 后， 我们 才不 再 依靠 平台 专属 的 扩展， 可以用 原生 C++ 直接 编写 多 线程 代码。 标准 C++ 线程 库 的 成型 历经 种种 取舍， 若要 掌握 其 设计 逻辑， 则 知晓 其 历史 渊源 颇为 重要。
>



RAII 手法。

> 例如， 通过 资源获取 即 初始化（ Resource Acquisition Is Initialization， RAII） 的 惯用 手法 进行 锁 操作， 它 确保 了 一旦 脱离 相关 作用域， 被 锁 的 互斥 就 自行 解开。 这项 设计 特别 重要， 为 许多 C++ 类 库 所 共有， 使 程序员 受益 良 多。
>



内存模型 为什么 会影响 线程库的实现，不是在 操作系统 API 上面封装一层就行了吗？

解答补充：内存模型应该是一种 语法传参的 东西。

> 随着 C++ 11 标准 的 发布， 上述 种种 弊端 被 一扫而空。 C++ 标准 库 不仅 规定了 内存 模型， 可以 区分 不同 线程， 还 扩 增 了 新 类， 分别 用于 线程 管 控（ 见 第 2 章）、 保护 共享 数据（ 见 第 3 章）、 同步 线程 间 操作（ 见 第 4 章） 以及 底层 原子 操作（ 见 第 5 章） 等。
>



抽象损失。

> 若要 实现 某项 功能， 代码 可以 借助 高级 工具， 或者 直接 使用 底层 工具。 两种 方式 的 运行 开销 不同， 该项 差异 叫作 抽象 损失[ 10]。 如果 读者 追求 极致 性能， 清楚 这点 便 尤为 重要。
>



注意 native_handle 函数 

>  为了 可以 便捷 利用 这些 工具， 同时 又能 照常 使用 标准 C++ 线程 库， C++ 线程 库 的 某些 型 别 有可能 提供 成员 函数 native_ handle()， 允许 它的 底层 直接 运用 平台 专属 的 API。 因其 本质 使然， 任何 采用 native_ handle() 的 操作 都 完全 依赖于 特定 平台，



获取  CPU 硬件线程的函数。

> td:: thread:: hardware_ concurrency()
>



读是可以并发的，写只能一个人写。

> 归根结底， 多 线程 共享 数据 的 问题 多 由 数据 改动 引发。 如果 所有 共享 数据 都是 只读 数据， 就不 会有 问题。 因为， 若 数据 被 某个 线程 读取， 无论 是否 存在 其他 线程 也在 读取， 该数 据 都不 会 受到影响。 然而， 如果 多个 线程 共享 数据， 只要 一个 线程 开始 改动 数据， 就会 带来 很多 隐患， 产生 麻烦。 鉴于 此， 我们 必须 小心、 谨慎， 保证 一切 都 正确 运作。
>



什么是锁粒度。

> 在 3. 2. 3 节 我们 就 曾经 提 过“ 锁 粒度”， 该 术语 描述 一个 锁 所 保护 的 数据 量， 但它 没有 严格 的 实质 定义。 粒度 精 细的 锁 保护 少量 数据， 而 粒度 粗 大的 锁 保护 大量 数据。
>



注意下面这两个函数。

> C++ 标准 委员会 相当 重视 以上 情况， 在 C++ 标准 库 中 提供 了 std:: once_ flag 类 和 std:: call_ once() 函数， 以 专门 处理 该 情况。
>



C++ 有共享锁与排他锁。C 语言也有读写锁，`pthread_rwlock_wrlock`

> C++ 17 标准 库 提供 了 两种 新的 互斥： std:: shared_ mutex 和 std:: shared_ timed_ mutex。 C++ 14 标准 库 只有 std:: shared_ timed_ mutex， 而 C++ 11 标准 库 都没 有。 假如 读者 的 编译器 尚未 支持 C++ 14， 那么 可以 考虑 使用 Boost 程序 库， 它 也 提供 了 这 两个 互斥。 它们 通过 提案 被 纳入 C++ 标准， 提案 的 原始 版本 即为 Boost 实现 的 依据。 std:: shared_ mutex 和 std:: shared_ timed_ mutex 的 区别 在于， 后者 支持 更多 操作（ 说明 见 4. 3 节）。 所以， 若无 须 进行 额外 操作， 则应 选用 std:: shared_ mutex， 其 在某 些 平台 上 可能 会 带来 性能 增益。
>



C++ 也有条件变量。

> C++ 标准 库 专门 为之 提供 了 处理 工具： 条件 变量（ conditional variable） 和 future。 C++ 标准 委员会 发布 的 并发 技术 规约 对这 些 工具 做了 扩展， 增加 了 更多 针对 future 的 操作， 还 提供 了 新式 的 同步 工具： 线程 闩（ latch） 和 线程 卡（ barrier）。
>



> C++ 标准 库 提供 了 条件 变量 的 两种 实现： std:: condition_ variable 和 std:: condition_ variable_ any。 它们 都在 标准 库 的 头 文件< condition_ variable> 内 声明。
>



C++ 语言的定位。

> 不论 其他 语言 如何 定位， C++ 都是 操作系统 级别 的 编程 语言。 C++ 标准 委员 会的 一个 目标 是 令 C++ 尽量 贴近 计算机 底层， 而 不必 改用 其他 更 低级 的 语言。 C++ 十分 灵活， 可满足 程序员 的 许多 需求， 包括 容许 他们 在 必要 时“ 贴近 计算机 底层 硬件”， 语言 本身 不应 构成 障碍。 原子 类型（ atomic） 及其 操作 应运而生， 提供 了 底层 同步同步 操作 的 功能， 其 常常 只需 一 两条 CPU 指令 即可 实现。
>



> std:: string 对象 s 则由 几 块 内存 区域 构成， 别的 数据 成员 都有 各自 的 内存 区域。
>



原子操作也只是强制访问次序。

> 5. 3 节 将 说明，如何 运用 原子 操作 强制 预定 访问 次序。



无锁代码是通过 DWCAS 实现的。

> 那些 硬件 平台 往往 都 具有 名为“ 双 字 比较- 交换” 的 指令（ Double- Word- Compare- And- Swap， DWCAS）， 它与 compare_ exchange_ xxx() 函数 对应。 我们将 在 第 7 章 见到， 这种 硬件 支持 有助于 编写 无 锁 代码。
>



> 我们将 在 第 7 章 重新 深入 细节， 充分 利用 第 5 章 所 介绍 的 原子 操作， 以 构建 无 锁 的 并发 数据 结构。
>



无锁结构只是摆脱锁，避免死锁，好像不能加大并发度。

> 只要 摆脱 锁， 实现 支持 安全 并发 访问 的 数据 结构， 就有 可能 解决 上述 问题。 这种 数据 结构 称为 无 锁 数据 结构。
>



> 算法 和数 据 结构 中 只要 采用 了 互斥、 条件 变量 或 future 进行 同步 操作， 就 称之为 阻塞 型 算法 和 阻塞 型 数据 结构。 如果 应用 程序 调用 某些 库 函数， 发起 调用 的 线程 便会 暂停 运行， 即在 函数 的 调用 点 阻塞， 等到 另一 线程 完成 某项 相关 操作， 阻塞 才会 解除， 前者 才会 继续 运行。 所以， 这种 库 函数 的 调用 被 命名为 阻塞 型 调用。 操作系统 往往 会把 被 阻塞 的 线程 彻底 暂停， 并将 其 时间 片 分配 给 其他 线程， 等到 有线 程 执行 了 恰当 的 操作， 阻塞 方 被 解除。 恰当 的 操作 可能 是 释放 互斥、 知 会 条件 变量， 或是 为 future 对象 装填 结果 值 而 令其 就绪。 算法 和数 据 结构 若 没有 采用 上述 阻塞 型 库 函数 调用， 则 对应 地 称为 非 阻塞 型（ nonblocking） 算法 和 非 阻塞 型 数据 结构。 我们 先来 考察 一些 非 阻塞 型 数据 结构， 不过， 其中 几种 还是 涉及 锁。
>



无锁数据结构，可能会导致 活 锁（ live lock） 

> 由于 无 锁 数据 结构 完全 不含 锁， 因此 不可能 出现 死锁， 但 活 锁（ live lock） 反而 有机 会 出现。 假设 两个 线程 同时 更改 同一 份数 据 结构， 若 它们 所做 的 改动 都 导致 对方 从头开始 操作， 那双 方 就会 反复 循环， 不断 重试， 这种 现象 即为 活 锁。 设想 两人 狭道 相逢， 若 他们 同时 前进， 便 都 堵在 路上， 只好 后退， 再试 图上 路。 除非 其中 一人 先行 通过（ 或 经过 协商， 或 快步 走完 狭道， 或 全 凭 运气）， 否则 循环 不停止。 在这 个 简单 的 例子 中， 活 锁 出现 与否 完全 取决于 线程 的 调度 次序， 故 往往 只会 短暂 存在。 因此， 它们 仅 降低 了 程序 性能， 尚不 至于 造成 严重 的 问题， 但我 们 仍需 小心 防范。 根据 定义， 在 免 等 代码 中， 执行 一项 操作 所需 步骤 的 数目 总是 被 设定 了 上限， 所以 不存在 活 锁 问题。 这种 模式 的 缺点 在于， 相关 算法 很可能 比 别的 算法 复杂， 即便 没有 其他 线程 同时 访问 数据 结构， 也 依然 要 执行 更多 步骤。
>



> 7. 1 节 曾 提到， 无 锁 数据 结构 依赖于 原子 操作， 以及 相关 的 内存 次序 约束， 后者 的 作用 是 令其 他 线程 按 正确 内存 次序 见到 数据 操作 的 过程。 默认 内存 次序 memory_ order_ seq_ cst 最易 于 分析 和 推理（ 请 记住， 全部 memory_ order_ seq_ cst 次序 的 操作 形成 确定 且 唯一 的 总 序列），
>



注意一下 BAB 问题。



OpenMP 编程

> 读者 若 曾经 从事 过 MPI 编程 或 OpenMP 编程， 就会 熟悉 上述 切分 的 结构：
>



C++ 实现线程池非常简单。

> 线程 池 最简单 的 实现 形式 是， 采用 数目 固定 的 工作 线程（ 往往 与 std:: thread:: hardware_ concurrency() 的 返回 值 相等）。 每当 有 任务 需要 处理 时， 我们 便 调用 某个 函数， 将它 放到 任务 队列 中 等待。 各 工作 线程 从 队列 中 领取 指定 的 任务 并 运行， 然后 再回 到 队列 领取 其他 任务。 最 简易 可行 的 线程 池 无法 等待 任务 完成。 若 我们 需要 这么 做， 就得 自己 操控 同步 动作。 
>



C++17 有并行算法库。



最好附录讲了右值。

![1-1](D:\0-博客\学习笔记\《C++并发编程实战》\1-1.png)

